{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-09T11:05:56.174844Z","iopub.execute_input":"2023-06-09T11:05:56.175625Z","iopub.status.idle":"2023-06-09T11:05:56.205610Z","shell.execute_reply.started":"2023-06-09T11:05:56.175590Z","shell.execute_reply":"2023-06-09T11:05:56.204801Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/glove-text-file/glove.6B.100d.txt\n/kaggle/input/files-of-data/valid_data.csv\n/kaggle/input/files-of-data/train_data.csv\n/kaggle/input/files-of-data/test_data.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"# import torch\n# from transformers import BertTokenizer, BertForSequenceClassification\n# import numpy as np\n\n# # Load pre-trained GloVe embeddings\n# glove_path = '/kaggle/input/glove-text-file/glove.6B.100d.txt'  # Path to your GloVe embeddings file\n# embedding_matrix[index] = np.reshape(glove_embeddings[word], (1, -1))\n\n# glove_embeddings = {}\n\n# with open(glove_path, 'r', encoding='utf-8') as f:\n#     for line in f:\n#         values = line.strip().split(' ')\n#         word = values[0]\n#         embeddings = np.asarray(values[1:], dtype=np.float32)\n#         glove_embeddings[word] = embeddings\n\n# # Load pre-trained BERT model and tokenizer\n# model_name = 'bert-base-uncased'\n# tokenizer = BertTokenizer.from_pretrained(model_name)\n# model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n\n# # Initialize BERT model's embedding layer with GloVe embeddings\n# vocab_size = tokenizer.vocab_size\n# embedding_dim = model.config.hidden_size\n\n# embedding_matrix = np.zeros((vocab_size, embedding_dim))\n\n# for word, index in tokenizer.get_vocab().items():\n#     if word in glove_embeddings:\n#         embedding_matrix[index] = glove_embeddings[word]\n\n# model.bert.embeddings.word_embeddings.weight.data = torch.tensor(embedding_matrix)\n\n# # Example user query\n# user_query = \"machine learning\"\n\n# # Tokenize user query\n# query_tokens = tokenizer.tokenize(user_query)\n# query_ids = tokenizer.convert_tokens_to_ids(query_tokens)\n# query_ids = tokenizer.build_inputs_with_special_tokens(query_ids)\n\n# # Convert query to tensor\n# query_tensor = torch.tensor([query_ids])\n\n# # Forward pass through the BERT model\n# outputs = model(query_tensor)\n\n# # Get the predicted probabilities and predicted label\n# probs = torch.softmax(outputs[0], dim=1)\n# predicted_label = torch.argmax(probs, dim=1).item()\n\n# # Convert label index to label text\n# label_map = {0: \"Not Relevant\", 1: \"Relevant\"}  # Modify as per your task\n# predicted_label_text = label_map[predicted_label]\n\n# # Print results\n# print(\"User Query:\", user_query)\n# print(\"Predicted Label:\", predicted_label_text)\n# print(\"Predicted Probabilities:\", probs.tolist())\n","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:06:00.087637Z","iopub.execute_input":"2023-06-09T11:06:00.088292Z","iopub.status.idle":"2023-06-09T11:06:00.103988Z","shell.execute_reply.started":"2023-06-09T11:06:00.088245Z","shell.execute_reply":"2023-06-09T11:06:00.102789Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!pip install --upgrade keras tensorflow","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:06:04.042807Z","iopub.execute_input":"2023-06-09T11:06:04.043180Z","iopub.status.idle":"2023-06-09T11:06:16.823418Z","shell.execute_reply.started":"2023-06-09T11:06:04.043150Z","shell.execute_reply":"2023-06-09T11:06:16.822231Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: keras in /opt/conda/lib/python3.10/site-packages (2.12.0)\nRequirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.12.0)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.3.3)\nRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.4.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.51.1)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.8.0)\nRequirement already satisfied: jax>=0.3.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.4.10)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.0)\nRequirement already satisfied: numpy<1.24,>=1.22 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.23.5)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (59.8.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: tensorboard<2.13,>=2.12 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.12.3)\nRequirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.12.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.3.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.5.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.31.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\nRequirement already satisfied: ml-dtypes>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow) (0.1.0)\nRequirement already satisfied: scipy>=1.7 in /opt/conda/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow) (1.10.1)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\nRequirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.28.2)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow) (3.0.9)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.2.7)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2023.5.7)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.2)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install keras","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:06:26.214315Z","iopub.execute_input":"2023-06-09T11:06:26.214687Z","iopub.status.idle":"2023-06-09T11:06:37.452992Z","shell.execute_reply.started":"2023-06-09T11:06:26.214650Z","shell.execute_reply":"2023-06-09T11:06:37.451879Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: keras in /opt/conda/lib/python3.10/site-packages (2.12.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import keras\nprint(keras.__version__) \n","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:06:41.292995Z","iopub.execute_input":"2023-06-09T11:06:41.293369Z","iopub.status.idle":"2023-06-09T11:06:48.948375Z","shell.execute_reply.started":"2023-06-09T11:06:41.293337Z","shell.execute_reply":"2023-06-09T11:06:48.947401Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"},{"name":"stdout","text":"2.12.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import re\nimport string\nimport numpy as np \nimport random\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom plotly import graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\nfrom collections import Counter\n\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\n\nfrom tqdm import tqdm\nimport os\nimport spacy\nfrom spacy.util import compounding\nfrom spacy.util import minibatch\n\nfrom collections import defaultdict\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.initializers import Constant\nfrom tensorflow.keras.layers import (LSTM, \n                                      Embedding, \n                                      BatchNormalization,\n                                      Dense, \n                                      TimeDistributed, \n                                      Dropout, \n                                      Bidirectional,\n                                      Flatten, \n                                      GlobalMaxPool1D)\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.optimizers import Adam\n\nfrom sklearn.metrics import (precision_score, \n                             recall_score, \n                             f1_score, \n                             classification_report,\n                             accuracy_score)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:06:51.516890Z","iopub.execute_input":"2023-06-09T11:06:51.517832Z","iopub.status.idle":"2023-06-09T11:06:59.671644Z","shell.execute_reply.started":"2023-06-09T11:06:51.517797Z","shell.execute_reply":"2023-06-09T11:06:59.670695Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(\"/kaggle/input/files-of-data/test_data.csv\",nrows=500 )\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:07:02.608829Z","iopub.execute_input":"2023-06-09T11:07:02.610016Z","iopub.status.idle":"2023-06-09T11:07:02.678850Z","shell.execute_reply.started":"2023-06-09T11:07:02.609974Z","shell.execute_reply":"2023-06-09T11:07:02.677952Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"              repo                                   path  \\\n0  soimort/you-get      src/you_get/extractors/youtube.py   \n1  soimort/you-get       src/you_get/extractors/miomio.py   \n2  soimort/you-get     src/you_get/extractors/fc2video.py   \n3  soimort/you-get     src/you_get/extractors/fc2video.py   \n4  soimort/you-get  src/you_get/extractors/dailymotion.py   \n\n                  func_name  \\\n0  YouTube.get_vid_from_url   \n1      sina_xml_to_url_list   \n2                  makeMimi   \n3         fc2video_download   \n4      dailymotion_download   \n\n                                     original_string language  \\\n0  def get_vid_from_url(url):\\n        \"\"\"Extract...   python   \n1  def sina_xml_to_url_list(xml_data):\\n    \"\"\"st...   python   \n2  def makeMimi(upid):\\n    \"\"\"From http://cdn37....   python   \n3  def fc2video_download(url, output_dir = '.', m...   python   \n4  def dailymotion_download(url, output_dir='.', ...   python   \n\n                                                code  \\\n0  def get_vid_from_url(url):\\n        \"\"\"Extract...   \n1  def sina_xml_to_url_list(xml_data):\\n    \"\"\"st...   \n2  def makeMimi(upid):\\n    \"\"\"From http://cdn37....   \n3  def fc2video_download(url, output_dir = '.', m...   \n4  def dailymotion_download(url, output_dir='.', ...   \n\n                                         code_tokens  \\\n0  ['def', 'get_vid_from_url', '(', 'url', ')', '...   \n1  ['def', 'sina_xml_to_url_list', '(', 'xml_data...   \n2  ['def', 'makeMimi', '(', 'upid', ')', ':', 'st...   \n3  ['def', 'fc2video_download', '(', 'url', ',', ...   \n4  ['def', 'dailymotion_download', '(', 'url', ',...   \n\n                                           docstring  \\\n0                        Extracts video ID from URL.   \n1  str->list\\n    Convert XML to URL List.\\n    F...   \n2  From http://cdn37.atwikiimg.com/sitescript/pub...   \n3                                            wrapper   \n4               Downloads Dailymotion videos by URL.   \n\n                                    docstring_tokens  \\\n0    ['Extracts', 'video', 'ID', 'from', 'URL', '.']   \n1  ['str', '-', '>', 'list', 'Convert', 'XML', 't...   \n2  ['From', 'http', ':', '//', 'cdn37', '.', 'atw...   \n3                                        ['wrapper']   \n4  ['Downloads', 'Dailymotion', 'videos', 'by', '...   \n\n                                        sha  \\\n0  b746ac01c9f39de94cac2d56f665285b0523b974   \n1  b746ac01c9f39de94cac2d56f665285b0523b974   \n2  b746ac01c9f39de94cac2d56f665285b0523b974   \n3  b746ac01c9f39de94cac2d56f665285b0523b974   \n4  b746ac01c9f39de94cac2d56f665285b0523b974   \n\n                                                 url partition  \n0  https://github.com/soimort/you-get/blob/b746ac...      test  \n1  https://github.com/soimort/you-get/blob/b746ac...      test  \n2  https://github.com/soimort/you-get/blob/b746ac...      test  \n3  https://github.com/soimort/you-get/blob/b746ac...      test  \n4  https://github.com/soimort/you-get/blob/b746ac...      test  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>repo</th>\n      <th>path</th>\n      <th>func_name</th>\n      <th>original_string</th>\n      <th>language</th>\n      <th>code</th>\n      <th>code_tokens</th>\n      <th>docstring</th>\n      <th>docstring_tokens</th>\n      <th>sha</th>\n      <th>url</th>\n      <th>partition</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>soimort/you-get</td>\n      <td>src/you_get/extractors/youtube.py</td>\n      <td>YouTube.get_vid_from_url</td>\n      <td>def get_vid_from_url(url):\\n        \"\"\"Extract...</td>\n      <td>python</td>\n      <td>def get_vid_from_url(url):\\n        \"\"\"Extract...</td>\n      <td>['def', 'get_vid_from_url', '(', 'url', ')', '...</td>\n      <td>Extracts video ID from URL.</td>\n      <td>['Extracts', 'video', 'ID', 'from', 'URL', '.']</td>\n      <td>b746ac01c9f39de94cac2d56f665285b0523b974</td>\n      <td>https://github.com/soimort/you-get/blob/b746ac...</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>soimort/you-get</td>\n      <td>src/you_get/extractors/miomio.py</td>\n      <td>sina_xml_to_url_list</td>\n      <td>def sina_xml_to_url_list(xml_data):\\n    \"\"\"st...</td>\n      <td>python</td>\n      <td>def sina_xml_to_url_list(xml_data):\\n    \"\"\"st...</td>\n      <td>['def', 'sina_xml_to_url_list', '(', 'xml_data...</td>\n      <td>str-&gt;list\\n    Convert XML to URL List.\\n    F...</td>\n      <td>['str', '-', '&gt;', 'list', 'Convert', 'XML', 't...</td>\n      <td>b746ac01c9f39de94cac2d56f665285b0523b974</td>\n      <td>https://github.com/soimort/you-get/blob/b746ac...</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>soimort/you-get</td>\n      <td>src/you_get/extractors/fc2video.py</td>\n      <td>makeMimi</td>\n      <td>def makeMimi(upid):\\n    \"\"\"From http://cdn37....</td>\n      <td>python</td>\n      <td>def makeMimi(upid):\\n    \"\"\"From http://cdn37....</td>\n      <td>['def', 'makeMimi', '(', 'upid', ')', ':', 'st...</td>\n      <td>From http://cdn37.atwikiimg.com/sitescript/pub...</td>\n      <td>['From', 'http', ':', '//', 'cdn37', '.', 'atw...</td>\n      <td>b746ac01c9f39de94cac2d56f665285b0523b974</td>\n      <td>https://github.com/soimort/you-get/blob/b746ac...</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>soimort/you-get</td>\n      <td>src/you_get/extractors/fc2video.py</td>\n      <td>fc2video_download</td>\n      <td>def fc2video_download(url, output_dir = '.', m...</td>\n      <td>python</td>\n      <td>def fc2video_download(url, output_dir = '.', m...</td>\n      <td>['def', 'fc2video_download', '(', 'url', ',', ...</td>\n      <td>wrapper</td>\n      <td>['wrapper']</td>\n      <td>b746ac01c9f39de94cac2d56f665285b0523b974</td>\n      <td>https://github.com/soimort/you-get/blob/b746ac...</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>soimort/you-get</td>\n      <td>src/you_get/extractors/dailymotion.py</td>\n      <td>dailymotion_download</td>\n      <td>def dailymotion_download(url, output_dir='.', ...</td>\n      <td>python</td>\n      <td>def dailymotion_download(url, output_dir='.', ...</td>\n      <td>['def', 'dailymotion_download', '(', 'url', ',...</td>\n      <td>Downloads Dailymotion videos by URL.</td>\n      <td>['Downloads', 'Dailymotion', 'videos', 'by', '...</td>\n      <td>b746ac01c9f39de94cac2d56f665285b0523b974</td>\n      <td>https://github.com/soimort/you-get/blob/b746ac...</td>\n      <td>test</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/files-of-data/train_data.csv\", nrows=1000)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:07:04.971900Z","iopub.execute_input":"2023-06-09T11:07:04.972613Z","iopub.status.idle":"2023-06-09T11:07:05.067221Z","shell.execute_reply.started":"2023-06-09T11:07:04.972578Z","shell.execute_reply":"2023-06-09T11:07:05.066297Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                        repo                              path  \\\n0  ageitgey/face_recognition  examples/face_recognition_knn.py   \n1  ageitgey/face_recognition  examples/face_recognition_knn.py   \n2  ageitgey/face_recognition  examples/face_recognition_knn.py   \n3  ageitgey/face_recognition           face_recognition/api.py   \n4  ageitgey/face_recognition           face_recognition/api.py   \n\n                         func_name  \\\n0                            train   \n1                          predict   \n2  show_prediction_labels_on_image   \n3                     _rect_to_css   \n4              _trim_css_to_bounds   \n\n                                     original_string language  \\\n0  def train(train_dir, model_save_path=None, n_n...   python   \n1  def predict(X_img_path, knn_clf=None, model_pa...   python   \n2  def show_prediction_labels_on_image(img_path, ...   python   \n3  def _rect_to_css(rect):\\n    \"\"\"\\n    Convert ...   python   \n4  def _trim_css_to_bounds(css, image_shape):\\n  ...   python   \n\n                                                code  \\\n0  def train(train_dir, model_save_path=None, n_n...   \n1  def predict(X_img_path, knn_clf=None, model_pa...   \n2  def show_prediction_labels_on_image(img_path, ...   \n3  def _rect_to_css(rect):\\n    \"\"\"\\n    Convert ...   \n4  def _trim_css_to_bounds(css, image_shape):\\n  ...   \n\n                                         code_tokens  \\\n0  ['def', 'train', '(', 'train_dir', ',', 'model...   \n1  ['def', 'predict', '(', 'X_img_path', ',', 'kn...   \n2  ['def', 'show_prediction_labels_on_image', '('...   \n3  ['def', '_rect_to_css', '(', 'rect', ')', ':',...   \n4  ['def', '_trim_css_to_bounds', '(', 'css', ','...   \n\n                                           docstring  \\\n0  Trains a k-nearest neighbors classifier for fa...   \n1  Recognizes faces in given image using a traine...   \n2  Shows the face recognition results visually.\\n...   \n3  Convert a dlib 'rect' object to a plain tuple ...   \n4  Make sure a tuple in (top, right, bottom, left...   \n\n                                    docstring_tokens  \\\n0  ['Trains', 'a', 'k', '-', 'nearest', 'neighbor...   \n1  ['Recognizes', 'faces', 'in', 'given', 'image'...   \n2  ['Shows', 'the', 'face', 'recognition', 'resul...   \n3  ['Convert', 'a', 'dlib', 'rect', 'object', 'to...   \n4  ['Make', 'sure', 'a', 'tuple', 'in', '(', 'top...   \n\n                                        sha  \\\n0  c96b010c02f15e8eeb0f71308c641179ac1f19bb   \n1  c96b010c02f15e8eeb0f71308c641179ac1f19bb   \n2  c96b010c02f15e8eeb0f71308c641179ac1f19bb   \n3  c96b010c02f15e8eeb0f71308c641179ac1f19bb   \n4  c96b010c02f15e8eeb0f71308c641179ac1f19bb   \n\n                                                 url partition  \n0  https://github.com/ageitgey/face_recognition/b...     train  \n1  https://github.com/ageitgey/face_recognition/b...     train  \n2  https://github.com/ageitgey/face_recognition/b...     train  \n3  https://github.com/ageitgey/face_recognition/b...     train  \n4  https://github.com/ageitgey/face_recognition/b...     train  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>repo</th>\n      <th>path</th>\n      <th>func_name</th>\n      <th>original_string</th>\n      <th>language</th>\n      <th>code</th>\n      <th>code_tokens</th>\n      <th>docstring</th>\n      <th>docstring_tokens</th>\n      <th>sha</th>\n      <th>url</th>\n      <th>partition</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ageitgey/face_recognition</td>\n      <td>examples/face_recognition_knn.py</td>\n      <td>train</td>\n      <td>def train(train_dir, model_save_path=None, n_n...</td>\n      <td>python</td>\n      <td>def train(train_dir, model_save_path=None, n_n...</td>\n      <td>['def', 'train', '(', 'train_dir', ',', 'model...</td>\n      <td>Trains a k-nearest neighbors classifier for fa...</td>\n      <td>['Trains', 'a', 'k', '-', 'nearest', 'neighbor...</td>\n      <td>c96b010c02f15e8eeb0f71308c641179ac1f19bb</td>\n      <td>https://github.com/ageitgey/face_recognition/b...</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ageitgey/face_recognition</td>\n      <td>examples/face_recognition_knn.py</td>\n      <td>predict</td>\n      <td>def predict(X_img_path, knn_clf=None, model_pa...</td>\n      <td>python</td>\n      <td>def predict(X_img_path, knn_clf=None, model_pa...</td>\n      <td>['def', 'predict', '(', 'X_img_path', ',', 'kn...</td>\n      <td>Recognizes faces in given image using a traine...</td>\n      <td>['Recognizes', 'faces', 'in', 'given', 'image'...</td>\n      <td>c96b010c02f15e8eeb0f71308c641179ac1f19bb</td>\n      <td>https://github.com/ageitgey/face_recognition/b...</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ageitgey/face_recognition</td>\n      <td>examples/face_recognition_knn.py</td>\n      <td>show_prediction_labels_on_image</td>\n      <td>def show_prediction_labels_on_image(img_path, ...</td>\n      <td>python</td>\n      <td>def show_prediction_labels_on_image(img_path, ...</td>\n      <td>['def', 'show_prediction_labels_on_image', '('...</td>\n      <td>Shows the face recognition results visually.\\n...</td>\n      <td>['Shows', 'the', 'face', 'recognition', 'resul...</td>\n      <td>c96b010c02f15e8eeb0f71308c641179ac1f19bb</td>\n      <td>https://github.com/ageitgey/face_recognition/b...</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ageitgey/face_recognition</td>\n      <td>face_recognition/api.py</td>\n      <td>_rect_to_css</td>\n      <td>def _rect_to_css(rect):\\n    \"\"\"\\n    Convert ...</td>\n      <td>python</td>\n      <td>def _rect_to_css(rect):\\n    \"\"\"\\n    Convert ...</td>\n      <td>['def', '_rect_to_css', '(', 'rect', ')', ':',...</td>\n      <td>Convert a dlib 'rect' object to a plain tuple ...</td>\n      <td>['Convert', 'a', 'dlib', 'rect', 'object', 'to...</td>\n      <td>c96b010c02f15e8eeb0f71308c641179ac1f19bb</td>\n      <td>https://github.com/ageitgey/face_recognition/b...</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ageitgey/face_recognition</td>\n      <td>face_recognition/api.py</td>\n      <td>_trim_css_to_bounds</td>\n      <td>def _trim_css_to_bounds(css, image_shape):\\n  ...</td>\n      <td>python</td>\n      <td>def _trim_css_to_bounds(css, image_shape):\\n  ...</td>\n      <td>['def', '_trim_css_to_bounds', '(', 'css', ','...</td>\n      <td>Make sure a tuple in (top, right, bottom, left...</td>\n      <td>['Make', 'sure', 'a', 'tuple', 'in', '(', 'top...</td>\n      <td>c96b010c02f15e8eeb0f71308c641179ac1f19bb</td>\n      <td>https://github.com/ageitgey/face_recognition/b...</td>\n      <td>train</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"balance_counts = train_df.groupby('docstring')['docstring'].agg('count').values\nbalance_counts","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:07:06.749594Z","iopub.execute_input":"2023-06-09T11:07:06.750425Z","iopub.status.idle":"2023-06-09T11:07:06.770695Z","shell.execute_reply.started":"2023-06-09T11:07:06.750393Z","shell.execute_reply":"2023-06-09T11:07:06.769800Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1,\n       1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"},"metadata":{}}]},{"cell_type":"code","source":"balance_counts = test_df.groupby('url')['url'].agg('count').values\nbalance_counts","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:07:08.408130Z","iopub.execute_input":"2023-06-09T11:07:08.408494Z","iopub.status.idle":"2023-06-09T11:07:08.418398Z","shell.execute_reply.started":"2023-06-09T11:07:08.408466Z","shell.execute_reply":"2023-06-09T11:07:08.417414Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"},"metadata":{}}]},{"cell_type":"code","source":"import plotly.graph_objects as go\nfig = go.Figure()\nfig.add_trace(go.Bar(\n    x=['docstring'],\n    y=[balance_counts[0]],\n    name='docstring',\n    text=[balance_counts[0]],\n    textposition='auto',\n))\nfig.add_trace(go.Bar(\n    x=['url'],\n    y=[balance_counts[1]],\n    name='url',\n    text=[balance_counts[1]],\n    textposition='auto',\n))\nfig.update_layout(\n    title='<span style=\"font-size:32px; font-family:Times New Roman\">Dataset distribution by target</span>'\n)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:07:09.764624Z","iopub.execute_input":"2023-06-09T11:07:09.765226Z","iopub.status.idle":"2023-06-09T11:07:09.867579Z","shell.execute_reply.started":"2023-06-09T11:07:09.765192Z","shell.execute_reply":"2023-06-09T11:07:09.866505Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/html":"        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-2.20.0.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        "},"metadata":{}},{"output_type":"display_data","data":{"text/html":"<div>                            <div id=\"a27bfb7e-ebe4-4b55-aecb-e2c961dd0da5\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a27bfb7e-ebe4-4b55-aecb-e2c961dd0da5\")) {                    Plotly.newPlot(                        \"a27bfb7e-ebe4-4b55-aecb-e2c961dd0da5\",                        [{\"name\":\"docstring\",\"text\":[\"1\"],\"textposition\":\"auto\",\"x\":[\"docstring\"],\"y\":[1],\"type\":\"bar\"},{\"name\":\"url\",\"text\":[\"1\"],\"textposition\":\"auto\",\"x\":[\"url\"],\"y\":[1],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"<span style=\\\"font-size:32px; font-family:Times New Roman\\\">Dataset distribution by target</span>\"}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('a27bfb7e-ebe4-4b55-aecb-e2c961dd0da5');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"},"metadata":{}}]},{"cell_type":"code","source":"# Special thanks to https://www.kaggle.com/tanulsingh077 for this function\ndef clean_docstring(docstring):\n    '''Make docstring lowercase, remove docstring in square brackets,remove links,remove punctuation\n    and remove words containing numbers.'''\n    docstring = str(docstring).lower()\n    docstring = re.sub('\\[.*?\\]', '', docstring)\n    docstring = re.sub('https?://\\S+|www\\.\\S+', '', docstring)\n    docstring = re.sub('<.*?>+', '', docstring)\n    docstring = re.sub('[%s]' % re.escape(string.punctuation), '', docstring)\n    docstring = re.sub('\\n', '', docstring)\n    docstring = re.sub('\\w*\\d\\w*', '', docstring)\n    return docstring  ","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:07:11.317448Z","iopub.execute_input":"2023-06-09T11:07:11.317808Z","iopub.status.idle":"2023-06-09T11:07:11.325488Z","shell.execute_reply.started":"2023-06-09T11:07:11.317777Z","shell.execute_reply":"2023-06-09T11:07:11.324018Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_df['docstring_clean'] = train_df['docstring'].apply(clean_docstring)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:07:12.900932Z","iopub.execute_input":"2023-06-09T11:07:12.901324Z","iopub.status.idle":"2023-06-09T11:07:13.054724Z","shell.execute_reply.started":"2023-06-09T11:07:12.901293Z","shell.execute_reply":"2023-06-09T11:07:13.053691Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                        repo                              path  \\\n0  ageitgey/face_recognition  examples/face_recognition_knn.py   \n1  ageitgey/face_recognition  examples/face_recognition_knn.py   \n2  ageitgey/face_recognition  examples/face_recognition_knn.py   \n3  ageitgey/face_recognition           face_recognition/api.py   \n4  ageitgey/face_recognition           face_recognition/api.py   \n\n                         func_name  \\\n0                            train   \n1                          predict   \n2  show_prediction_labels_on_image   \n3                     _rect_to_css   \n4              _trim_css_to_bounds   \n\n                                     original_string language  \\\n0  def train(train_dir, model_save_path=None, n_n...   python   \n1  def predict(X_img_path, knn_clf=None, model_pa...   python   \n2  def show_prediction_labels_on_image(img_path, ...   python   \n3  def _rect_to_css(rect):\\n    \"\"\"\\n    Convert ...   python   \n4  def _trim_css_to_bounds(css, image_shape):\\n  ...   python   \n\n                                                code  \\\n0  def train(train_dir, model_save_path=None, n_n...   \n1  def predict(X_img_path, knn_clf=None, model_pa...   \n2  def show_prediction_labels_on_image(img_path, ...   \n3  def _rect_to_css(rect):\\n    \"\"\"\\n    Convert ...   \n4  def _trim_css_to_bounds(css, image_shape):\\n  ...   \n\n                                         code_tokens  \\\n0  ['def', 'train', '(', 'train_dir', ',', 'model...   \n1  ['def', 'predict', '(', 'X_img_path', ',', 'kn...   \n2  ['def', 'show_prediction_labels_on_image', '('...   \n3  ['def', '_rect_to_css', '(', 'rect', ')', ':',...   \n4  ['def', '_trim_css_to_bounds', '(', 'css', ','...   \n\n                                           docstring  \\\n0  Trains a k-nearest neighbors classifier for fa...   \n1  Recognizes faces in given image using a traine...   \n2  Shows the face recognition results visually.\\n...   \n3  Convert a dlib 'rect' object to a plain tuple ...   \n4  Make sure a tuple in (top, right, bottom, left...   \n\n                                    docstring_tokens  \\\n0  ['Trains', 'a', 'k', '-', 'nearest', 'neighbor...   \n1  ['Recognizes', 'faces', 'in', 'given', 'image'...   \n2  ['Shows', 'the', 'face', 'recognition', 'resul...   \n3  ['Convert', 'a', 'dlib', 'rect', 'object', 'to...   \n4  ['Make', 'sure', 'a', 'tuple', 'in', '(', 'top...   \n\n                                        sha  \\\n0  c96b010c02f15e8eeb0f71308c641179ac1f19bb   \n1  c96b010c02f15e8eeb0f71308c641179ac1f19bb   \n2  c96b010c02f15e8eeb0f71308c641179ac1f19bb   \n3  c96b010c02f15e8eeb0f71308c641179ac1f19bb   \n4  c96b010c02f15e8eeb0f71308c641179ac1f19bb   \n\n                                                 url partition  \\\n0  https://github.com/ageitgey/face_recognition/b...     train   \n1  https://github.com/ageitgey/face_recognition/b...     train   \n2  https://github.com/ageitgey/face_recognition/b...     train   \n3  https://github.com/ageitgey/face_recognition/b...     train   \n4  https://github.com/ageitgey/face_recognition/b...     train   \n\n                                     docstring_clean  \n0  trains a knearest neighbors classifier for fac...  \n1  recognizes faces in given image using a traine...  \n2  shows the face recognition results visually   ...  \n3  convert a dlib rect object to a plain tuple in...  \n4  make sure a tuple in top right bottom left ord...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>repo</th>\n      <th>path</th>\n      <th>func_name</th>\n      <th>original_string</th>\n      <th>language</th>\n      <th>code</th>\n      <th>code_tokens</th>\n      <th>docstring</th>\n      <th>docstring_tokens</th>\n      <th>sha</th>\n      <th>url</th>\n      <th>partition</th>\n      <th>docstring_clean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ageitgey/face_recognition</td>\n      <td>examples/face_recognition_knn.py</td>\n      <td>train</td>\n      <td>def train(train_dir, model_save_path=None, n_n...</td>\n      <td>python</td>\n      <td>def train(train_dir, model_save_path=None, n_n...</td>\n      <td>['def', 'train', '(', 'train_dir', ',', 'model...</td>\n      <td>Trains a k-nearest neighbors classifier for fa...</td>\n      <td>['Trains', 'a', 'k', '-', 'nearest', 'neighbor...</td>\n      <td>c96b010c02f15e8eeb0f71308c641179ac1f19bb</td>\n      <td>https://github.com/ageitgey/face_recognition/b...</td>\n      <td>train</td>\n      <td>trains a knearest neighbors classifier for fac...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ageitgey/face_recognition</td>\n      <td>examples/face_recognition_knn.py</td>\n      <td>predict</td>\n      <td>def predict(X_img_path, knn_clf=None, model_pa...</td>\n      <td>python</td>\n      <td>def predict(X_img_path, knn_clf=None, model_pa...</td>\n      <td>['def', 'predict', '(', 'X_img_path', ',', 'kn...</td>\n      <td>Recognizes faces in given image using a traine...</td>\n      <td>['Recognizes', 'faces', 'in', 'given', 'image'...</td>\n      <td>c96b010c02f15e8eeb0f71308c641179ac1f19bb</td>\n      <td>https://github.com/ageitgey/face_recognition/b...</td>\n      <td>train</td>\n      <td>recognizes faces in given image using a traine...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ageitgey/face_recognition</td>\n      <td>examples/face_recognition_knn.py</td>\n      <td>show_prediction_labels_on_image</td>\n      <td>def show_prediction_labels_on_image(img_path, ...</td>\n      <td>python</td>\n      <td>def show_prediction_labels_on_image(img_path, ...</td>\n      <td>['def', 'show_prediction_labels_on_image', '('...</td>\n      <td>Shows the face recognition results visually.\\n...</td>\n      <td>['Shows', 'the', 'face', 'recognition', 'resul...</td>\n      <td>c96b010c02f15e8eeb0f71308c641179ac1f19bb</td>\n      <td>https://github.com/ageitgey/face_recognition/b...</td>\n      <td>train</td>\n      <td>shows the face recognition results visually   ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ageitgey/face_recognition</td>\n      <td>face_recognition/api.py</td>\n      <td>_rect_to_css</td>\n      <td>def _rect_to_css(rect):\\n    \"\"\"\\n    Convert ...</td>\n      <td>python</td>\n      <td>def _rect_to_css(rect):\\n    \"\"\"\\n    Convert ...</td>\n      <td>['def', '_rect_to_css', '(', 'rect', ')', ':',...</td>\n      <td>Convert a dlib 'rect' object to a plain tuple ...</td>\n      <td>['Convert', 'a', 'dlib', 'rect', 'object', 'to...</td>\n      <td>c96b010c02f15e8eeb0f71308c641179ac1f19bb</td>\n      <td>https://github.com/ageitgey/face_recognition/b...</td>\n      <td>train</td>\n      <td>convert a dlib rect object to a plain tuple in...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ageitgey/face_recognition</td>\n      <td>face_recognition/api.py</td>\n      <td>_trim_css_to_bounds</td>\n      <td>def _trim_css_to_bounds(css, image_shape):\\n  ...</td>\n      <td>python</td>\n      <td>def _trim_css_to_bounds(css, image_shape):\\n  ...</td>\n      <td>['def', '_trim_css_to_bounds', '(', 'css', ','...</td>\n      <td>Make sure a tuple in (top, right, bottom, left...</td>\n      <td>['Make', 'sure', 'a', 'tuple', 'in', '(', 'top...</td>\n      <td>c96b010c02f15e8eeb0f71308c641179ac1f19bb</td>\n      <td>https://github.com/ageitgey/face_recognition/b...</td>\n      <td>train</td>\n      <td>make sure a tuple in top right bottom left ord...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test_df['docstring_clean'] = test_df['docstring'].apply(clean_docstring)\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:07:14.541316Z","iopub.execute_input":"2023-06-09T11:07:14.541683Z","iopub.status.idle":"2023-06-09T11:07:14.607253Z","shell.execute_reply.started":"2023-06-09T11:07:14.541652Z","shell.execute_reply":"2023-06-09T11:07:14.606113Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"              repo                                   path  \\\n0  soimort/you-get      src/you_get/extractors/youtube.py   \n1  soimort/you-get       src/you_get/extractors/miomio.py   \n2  soimort/you-get     src/you_get/extractors/fc2video.py   \n3  soimort/you-get     src/you_get/extractors/fc2video.py   \n4  soimort/you-get  src/you_get/extractors/dailymotion.py   \n\n                  func_name  \\\n0  YouTube.get_vid_from_url   \n1      sina_xml_to_url_list   \n2                  makeMimi   \n3         fc2video_download   \n4      dailymotion_download   \n\n                                     original_string language  \\\n0  def get_vid_from_url(url):\\n        \"\"\"Extract...   python   \n1  def sina_xml_to_url_list(xml_data):\\n    \"\"\"st...   python   \n2  def makeMimi(upid):\\n    \"\"\"From http://cdn37....   python   \n3  def fc2video_download(url, output_dir = '.', m...   python   \n4  def dailymotion_download(url, output_dir='.', ...   python   \n\n                                                code  \\\n0  def get_vid_from_url(url):\\n        \"\"\"Extract...   \n1  def sina_xml_to_url_list(xml_data):\\n    \"\"\"st...   \n2  def makeMimi(upid):\\n    \"\"\"From http://cdn37....   \n3  def fc2video_download(url, output_dir = '.', m...   \n4  def dailymotion_download(url, output_dir='.', ...   \n\n                                         code_tokens  \\\n0  ['def', 'get_vid_from_url', '(', 'url', ')', '...   \n1  ['def', 'sina_xml_to_url_list', '(', 'xml_data...   \n2  ['def', 'makeMimi', '(', 'upid', ')', ':', 'st...   \n3  ['def', 'fc2video_download', '(', 'url', ',', ...   \n4  ['def', 'dailymotion_download', '(', 'url', ',...   \n\n                                           docstring  \\\n0                        Extracts video ID from URL.   \n1  str->list\\n    Convert XML to URL List.\\n    F...   \n2  From http://cdn37.atwikiimg.com/sitescript/pub...   \n3                                            wrapper   \n4               Downloads Dailymotion videos by URL.   \n\n                                    docstring_tokens  \\\n0    ['Extracts', 'video', 'ID', 'from', 'URL', '.']   \n1  ['str', '-', '>', 'list', 'Convert', 'XML', 't...   \n2  ['From', 'http', ':', '//', 'cdn37', '.', 'atw...   \n3                                        ['wrapper']   \n4  ['Downloads', 'Dailymotion', 'videos', 'by', '...   \n\n                                        sha  \\\n0  b746ac01c9f39de94cac2d56f665285b0523b974   \n1  b746ac01c9f39de94cac2d56f665285b0523b974   \n2  b746ac01c9f39de94cac2d56f665285b0523b974   \n3  b746ac01c9f39de94cac2d56f665285b0523b974   \n4  b746ac01c9f39de94cac2d56f665285b0523b974   \n\n                                                 url partition  \\\n0  https://github.com/soimort/you-get/blob/b746ac...      test   \n1  https://github.com/soimort/you-get/blob/b746ac...      test   \n2  https://github.com/soimort/you-get/blob/b746ac...      test   \n3  https://github.com/soimort/you-get/blob/b746ac...      test   \n4  https://github.com/soimort/you-get/blob/b746ac...      test   \n\n                                     docstring_clean  \n0                         extracts video id from url  \n1  strlist    convert xml to url list    from bil...  \n2                                 from     also       \n3                                            wrapper  \n4                downloads dailymotion videos by url  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>repo</th>\n      <th>path</th>\n      <th>func_name</th>\n      <th>original_string</th>\n      <th>language</th>\n      <th>code</th>\n      <th>code_tokens</th>\n      <th>docstring</th>\n      <th>docstring_tokens</th>\n      <th>sha</th>\n      <th>url</th>\n      <th>partition</th>\n      <th>docstring_clean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>soimort/you-get</td>\n      <td>src/you_get/extractors/youtube.py</td>\n      <td>YouTube.get_vid_from_url</td>\n      <td>def get_vid_from_url(url):\\n        \"\"\"Extract...</td>\n      <td>python</td>\n      <td>def get_vid_from_url(url):\\n        \"\"\"Extract...</td>\n      <td>['def', 'get_vid_from_url', '(', 'url', ')', '...</td>\n      <td>Extracts video ID from URL.</td>\n      <td>['Extracts', 'video', 'ID', 'from', 'URL', '.']</td>\n      <td>b746ac01c9f39de94cac2d56f665285b0523b974</td>\n      <td>https://github.com/soimort/you-get/blob/b746ac...</td>\n      <td>test</td>\n      <td>extracts video id from url</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>soimort/you-get</td>\n      <td>src/you_get/extractors/miomio.py</td>\n      <td>sina_xml_to_url_list</td>\n      <td>def sina_xml_to_url_list(xml_data):\\n    \"\"\"st...</td>\n      <td>python</td>\n      <td>def sina_xml_to_url_list(xml_data):\\n    \"\"\"st...</td>\n      <td>['def', 'sina_xml_to_url_list', '(', 'xml_data...</td>\n      <td>str-&gt;list\\n    Convert XML to URL List.\\n    F...</td>\n      <td>['str', '-', '&gt;', 'list', 'Convert', 'XML', 't...</td>\n      <td>b746ac01c9f39de94cac2d56f665285b0523b974</td>\n      <td>https://github.com/soimort/you-get/blob/b746ac...</td>\n      <td>test</td>\n      <td>strlist    convert xml to url list    from bil...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>soimort/you-get</td>\n      <td>src/you_get/extractors/fc2video.py</td>\n      <td>makeMimi</td>\n      <td>def makeMimi(upid):\\n    \"\"\"From http://cdn37....</td>\n      <td>python</td>\n      <td>def makeMimi(upid):\\n    \"\"\"From http://cdn37....</td>\n      <td>['def', 'makeMimi', '(', 'upid', ')', ':', 'st...</td>\n      <td>From http://cdn37.atwikiimg.com/sitescript/pub...</td>\n      <td>['From', 'http', ':', '//', 'cdn37', '.', 'atw...</td>\n      <td>b746ac01c9f39de94cac2d56f665285b0523b974</td>\n      <td>https://github.com/soimort/you-get/blob/b746ac...</td>\n      <td>test</td>\n      <td>from     also</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>soimort/you-get</td>\n      <td>src/you_get/extractors/fc2video.py</td>\n      <td>fc2video_download</td>\n      <td>def fc2video_download(url, output_dir = '.', m...</td>\n      <td>python</td>\n      <td>def fc2video_download(url, output_dir = '.', m...</td>\n      <td>['def', 'fc2video_download', '(', 'url', ',', ...</td>\n      <td>wrapper</td>\n      <td>['wrapper']</td>\n      <td>b746ac01c9f39de94cac2d56f665285b0523b974</td>\n      <td>https://github.com/soimort/you-get/blob/b746ac...</td>\n      <td>test</td>\n      <td>wrapper</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>soimort/you-get</td>\n      <td>src/you_get/extractors/dailymotion.py</td>\n      <td>dailymotion_download</td>\n      <td>def dailymotion_download(url, output_dir='.', ...</td>\n      <td>python</td>\n      <td>def dailymotion_download(url, output_dir='.', ...</td>\n      <td>['def', 'dailymotion_download', '(', 'url', ',...</td>\n      <td>Downloads Dailymotion videos by URL.</td>\n      <td>['Downloads', 'Dailymotion', 'videos', 'by', '...</td>\n      <td>b746ac01c9f39de94cac2d56f665285b0523b974</td>\n      <td>https://github.com/soimort/you-get/blob/b746ac...</td>\n      <td>test</td>\n      <td>downloads dailymotion videos by url</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"stop_words = stopwords.words('english')\nmore_stopwords = ['u', 'im', 'c']\nstop_words = stop_words + more_stopwords\n\ndef remove_stopwords(docstring):\n    docstring = ' '.join(word for word in docstring.split(' ') if word not in stop_words)\n    return docstring\n    \ntest_df['docstring_clean'] = test_df['docstring_clean'].apply(remove_stopwords)\ntrain_df['docstring_clean'] = train_df['docstring_clean'].apply(remove_stopwords)","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:07:16.770782Z","iopub.execute_input":"2023-06-09T11:07:16.771155Z","iopub.status.idle":"2023-06-09T11:07:17.090814Z","shell.execute_reply.started":"2023-06-09T11:07:16.771119Z","shell.execute_reply":"2023-06-09T11:07:17.089742Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"stemmer = nltk.SnowballStemmer(\"english\")\n\ndef stemm_docstring(docstring):\n    docstring = ' '.join(stemmer.stem(word) for word in docstring.split(' '))\n    return docstring","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:07:18.266882Z","iopub.execute_input":"2023-06-09T11:07:18.267575Z","iopub.status.idle":"2023-06-09T11:07:18.272864Z","shell.execute_reply.started":"2023-06-09T11:07:18.267542Z","shell.execute_reply":"2023-06-09T11:07:18.271820Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"test_df['docstring_clean'] = test_df['docstring_clean'].apply(stemm_docstring)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:07:20.114861Z","iopub.execute_input":"2023-06-09T11:07:20.115534Z","iopub.status.idle":"2023-06-09T11:07:20.365035Z","shell.execute_reply.started":"2023-06-09T11:07:20.115502Z","shell.execute_reply":"2023-06-09T11:07:20.364104Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train_df['docstring_clean'] = train_df['docstring_clean'].apply(stemm_docstring)","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:07:21.988031Z","iopub.execute_input":"2023-06-09T11:07:21.988391Z","iopub.status.idle":"2023-06-09T11:07:22.636515Z","shell.execute_reply.started":"2023-06-09T11:07:21.988362Z","shell.execute_reply":"2023-06-09T11:07:22.635551Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def preprocess_data(docstring):\n    # Clean puntuation, urls, and so on\n    docstring = clean_docstring(docstring)\n    # Remove stopwords\n    docstring = ' '.join(word for word in docstring.split(' ') if word not in stop_words)\n    # Stemm all the words in the sentence\n    docstring = ' '.join(stemmer.stem(word) for word in docstring.split(' '))\n    \n    return docstring","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:07:24.140369Z","iopub.execute_input":"2023-06-09T11:07:24.142913Z","iopub.status.idle":"2023-06-09T11:07:24.149753Z","shell.execute_reply.started":"2023-06-09T11:07:24.142879Z","shell.execute_reply":"2023-06-09T11:07:24.148732Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"test_df['docstring_clean'] = test_df['docstring_clean'].apply(preprocess_data)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:07:26.245839Z","iopub.execute_input":"2023-06-09T11:07:26.246514Z","iopub.status.idle":"2023-06-09T11:07:26.586417Z","shell.execute_reply.started":"2023-06-09T11:07:26.246481Z","shell.execute_reply":"2023-06-09T11:07:26.585454Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"train_df['docstring_clean'] = train_df['docstring_clean'].apply(preprocess_data)","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:07:27.957818Z","iopub.execute_input":"2023-06-09T11:07:27.958498Z","iopub.status.idle":"2023-06-09T11:07:28.891548Z","shell.execute_reply.started":"2023-06-09T11:07:27.958464Z","shell.execute_reply":"2023-06-09T11:07:28.890374Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\nle.fit(train_df['url'])\n\n\ntrain_df['url_encoded'] = le.transform(train_df['url'])\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:07:30.558357Z","iopub.execute_input":"2023-06-09T11:07:30.559373Z","iopub.status.idle":"2023-06-09T11:07:30.595118Z","shell.execute_reply.started":"2023-06-09T11:07:30.559333Z","shell.execute_reply":"2023-06-09T11:07:30.593118Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"                        repo                              path  \\\n0  ageitgey/face_recognition  examples/face_recognition_knn.py   \n1  ageitgey/face_recognition  examples/face_recognition_knn.py   \n2  ageitgey/face_recognition  examples/face_recognition_knn.py   \n3  ageitgey/face_recognition           face_recognition/api.py   \n4  ageitgey/face_recognition           face_recognition/api.py   \n\n                         func_name  \\\n0                            train   \n1                          predict   \n2  show_prediction_labels_on_image   \n3                     _rect_to_css   \n4              _trim_css_to_bounds   \n\n                                     original_string language  \\\n0  def train(train_dir, model_save_path=None, n_n...   python   \n1  def predict(X_img_path, knn_clf=None, model_pa...   python   \n2  def show_prediction_labels_on_image(img_path, ...   python   \n3  def _rect_to_css(rect):\\n    \"\"\"\\n    Convert ...   python   \n4  def _trim_css_to_bounds(css, image_shape):\\n  ...   python   \n\n                                                code  \\\n0  def train(train_dir, model_save_path=None, n_n...   \n1  def predict(X_img_path, knn_clf=None, model_pa...   \n2  def show_prediction_labels_on_image(img_path, ...   \n3  def _rect_to_css(rect):\\n    \"\"\"\\n    Convert ...   \n4  def _trim_css_to_bounds(css, image_shape):\\n  ...   \n\n                                         code_tokens  \\\n0  ['def', 'train', '(', 'train_dir', ',', 'model...   \n1  ['def', 'predict', '(', 'X_img_path', ',', 'kn...   \n2  ['def', 'show_prediction_labels_on_image', '('...   \n3  ['def', '_rect_to_css', '(', 'rect', ')', ':',...   \n4  ['def', '_trim_css_to_bounds', '(', 'css', ','...   \n\n                                           docstring  \\\n0  Trains a k-nearest neighbors classifier for fa...   \n1  Recognizes faces in given image using a traine...   \n2  Shows the face recognition results visually.\\n...   \n3  Convert a dlib 'rect' object to a plain tuple ...   \n4  Make sure a tuple in (top, right, bottom, left...   \n\n                                    docstring_tokens  \\\n0  ['Trains', 'a', 'k', '-', 'nearest', 'neighbor...   \n1  ['Recognizes', 'faces', 'in', 'given', 'image'...   \n2  ['Shows', 'the', 'face', 'recognition', 'resul...   \n3  ['Convert', 'a', 'dlib', 'rect', 'object', 'to...   \n4  ['Make', 'sure', 'a', 'tuple', 'in', '(', 'top...   \n\n                                        sha  \\\n0  c96b010c02f15e8eeb0f71308c641179ac1f19bb   \n1  c96b010c02f15e8eeb0f71308c641179ac1f19bb   \n2  c96b010c02f15e8eeb0f71308c641179ac1f19bb   \n3  c96b010c02f15e8eeb0f71308c641179ac1f19bb   \n4  c96b010c02f15e8eeb0f71308c641179ac1f19bb   \n\n                                                 url partition  \\\n0  https://github.com/ageitgey/face_recognition/b...     train   \n1  https://github.com/ageitgey/face_recognition/b...     train   \n2  https://github.com/ageitgey/face_recognition/b...     train   \n3  https://github.com/ageitgey/face_recognition/b...     train   \n4  https://github.com/ageitgey/face_recognition/b...     train   \n\n                                     docstring_clean  url_encoded  \n0  train knearest neighbor classifi face recognit...            2  \n1  recogn face given imag use train knn classifi ...            0  \n2  show face recognit result visual    param imgp...            1  \n3  convert dlib rect object plain tupl top right ...            7  \n4  make sure tupl top right bottom left order wit...            8  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>repo</th>\n      <th>path</th>\n      <th>func_name</th>\n      <th>original_string</th>\n      <th>language</th>\n      <th>code</th>\n      <th>code_tokens</th>\n      <th>docstring</th>\n      <th>docstring_tokens</th>\n      <th>sha</th>\n      <th>url</th>\n      <th>partition</th>\n      <th>docstring_clean</th>\n      <th>url_encoded</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ageitgey/face_recognition</td>\n      <td>examples/face_recognition_knn.py</td>\n      <td>train</td>\n      <td>def train(train_dir, model_save_path=None, n_n...</td>\n      <td>python</td>\n      <td>def train(train_dir, model_save_path=None, n_n...</td>\n      <td>['def', 'train', '(', 'train_dir', ',', 'model...</td>\n      <td>Trains a k-nearest neighbors classifier for fa...</td>\n      <td>['Trains', 'a', 'k', '-', 'nearest', 'neighbor...</td>\n      <td>c96b010c02f15e8eeb0f71308c641179ac1f19bb</td>\n      <td>https://github.com/ageitgey/face_recognition/b...</td>\n      <td>train</td>\n      <td>train knearest neighbor classifi face recognit...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ageitgey/face_recognition</td>\n      <td>examples/face_recognition_knn.py</td>\n      <td>predict</td>\n      <td>def predict(X_img_path, knn_clf=None, model_pa...</td>\n      <td>python</td>\n      <td>def predict(X_img_path, knn_clf=None, model_pa...</td>\n      <td>['def', 'predict', '(', 'X_img_path', ',', 'kn...</td>\n      <td>Recognizes faces in given image using a traine...</td>\n      <td>['Recognizes', 'faces', 'in', 'given', 'image'...</td>\n      <td>c96b010c02f15e8eeb0f71308c641179ac1f19bb</td>\n      <td>https://github.com/ageitgey/face_recognition/b...</td>\n      <td>train</td>\n      <td>recogn face given imag use train knn classifi ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ageitgey/face_recognition</td>\n      <td>examples/face_recognition_knn.py</td>\n      <td>show_prediction_labels_on_image</td>\n      <td>def show_prediction_labels_on_image(img_path, ...</td>\n      <td>python</td>\n      <td>def show_prediction_labels_on_image(img_path, ...</td>\n      <td>['def', 'show_prediction_labels_on_image', '('...</td>\n      <td>Shows the face recognition results visually.\\n...</td>\n      <td>['Shows', 'the', 'face', 'recognition', 'resul...</td>\n      <td>c96b010c02f15e8eeb0f71308c641179ac1f19bb</td>\n      <td>https://github.com/ageitgey/face_recognition/b...</td>\n      <td>train</td>\n      <td>show face recognit result visual    param imgp...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ageitgey/face_recognition</td>\n      <td>face_recognition/api.py</td>\n      <td>_rect_to_css</td>\n      <td>def _rect_to_css(rect):\\n    \"\"\"\\n    Convert ...</td>\n      <td>python</td>\n      <td>def _rect_to_css(rect):\\n    \"\"\"\\n    Convert ...</td>\n      <td>['def', '_rect_to_css', '(', 'rect', ')', ':',...</td>\n      <td>Convert a dlib 'rect' object to a plain tuple ...</td>\n      <td>['Convert', 'a', 'dlib', 'rect', 'object', 'to...</td>\n      <td>c96b010c02f15e8eeb0f71308c641179ac1f19bb</td>\n      <td>https://github.com/ageitgey/face_recognition/b...</td>\n      <td>train</td>\n      <td>convert dlib rect object plain tupl top right ...</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ageitgey/face_recognition</td>\n      <td>face_recognition/api.py</td>\n      <td>_trim_css_to_bounds</td>\n      <td>def _trim_css_to_bounds(css, image_shape):\\n  ...</td>\n      <td>python</td>\n      <td>def _trim_css_to_bounds(css, image_shape):\\n  ...</td>\n      <td>['def', '_trim_css_to_bounds', '(', 'css', ','...</td>\n      <td>Make sure a tuple in (top, right, bottom, left...</td>\n      <td>['Make', 'sure', 'a', 'tuple', 'in', '(', 'top...</td>\n      <td>c96b010c02f15e8eeb0f71308c641179ac1f19bb</td>\n      <td>https://github.com/ageitgey/face_recognition/b...</td>\n      <td>train</td>\n      <td>make sure tupl top right bottom left order wit...</td>\n      <td>8</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"le = LabelEncoder()\nle.fit(test_df['url'])\n\n\ntest_df['url_encoded'] = le.transform(test_df['url'])\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:07:31.923763Z","iopub.execute_input":"2023-06-09T11:07:31.924720Z","iopub.status.idle":"2023-06-09T11:07:31.944974Z","shell.execute_reply.started":"2023-06-09T11:07:31.924679Z","shell.execute_reply":"2023-06-09T11:07:31.944015Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"              repo                                   path  \\\n0  soimort/you-get      src/you_get/extractors/youtube.py   \n1  soimort/you-get       src/you_get/extractors/miomio.py   \n2  soimort/you-get     src/you_get/extractors/fc2video.py   \n3  soimort/you-get     src/you_get/extractors/fc2video.py   \n4  soimort/you-get  src/you_get/extractors/dailymotion.py   \n\n                  func_name  \\\n0  YouTube.get_vid_from_url   \n1      sina_xml_to_url_list   \n2                  makeMimi   \n3         fc2video_download   \n4      dailymotion_download   \n\n                                     original_string language  \\\n0  def get_vid_from_url(url):\\n        \"\"\"Extract...   python   \n1  def sina_xml_to_url_list(xml_data):\\n    \"\"\"st...   python   \n2  def makeMimi(upid):\\n    \"\"\"From http://cdn37....   python   \n3  def fc2video_download(url, output_dir = '.', m...   python   \n4  def dailymotion_download(url, output_dir='.', ...   python   \n\n                                                code  \\\n0  def get_vid_from_url(url):\\n        \"\"\"Extract...   \n1  def sina_xml_to_url_list(xml_data):\\n    \"\"\"st...   \n2  def makeMimi(upid):\\n    \"\"\"From http://cdn37....   \n3  def fc2video_download(url, output_dir = '.', m...   \n4  def dailymotion_download(url, output_dir='.', ...   \n\n                                         code_tokens  \\\n0  ['def', 'get_vid_from_url', '(', 'url', ')', '...   \n1  ['def', 'sina_xml_to_url_list', '(', 'xml_data...   \n2  ['def', 'makeMimi', '(', 'upid', ')', ':', 'st...   \n3  ['def', 'fc2video_download', '(', 'url', ',', ...   \n4  ['def', 'dailymotion_download', '(', 'url', ',...   \n\n                                           docstring  \\\n0                        Extracts video ID from URL.   \n1  str->list\\n    Convert XML to URL List.\\n    F...   \n2  From http://cdn37.atwikiimg.com/sitescript/pub...   \n3                                            wrapper   \n4               Downloads Dailymotion videos by URL.   \n\n                                    docstring_tokens  \\\n0    ['Extracts', 'video', 'ID', 'from', 'URL', '.']   \n1  ['str', '-', '>', 'list', 'Convert', 'XML', 't...   \n2  ['From', 'http', ':', '//', 'cdn37', '.', 'atw...   \n3                                        ['wrapper']   \n4  ['Downloads', 'Dailymotion', 'videos', 'by', '...   \n\n                                        sha  \\\n0  b746ac01c9f39de94cac2d56f665285b0523b974   \n1  b746ac01c9f39de94cac2d56f665285b0523b974   \n2  b746ac01c9f39de94cac2d56f665285b0523b974   \n3  b746ac01c9f39de94cac2d56f665285b0523b974   \n4  b746ac01c9f39de94cac2d56f665285b0523b974   \n\n                                                 url partition  \\\n0  https://github.com/soimort/you-get/blob/b746ac...      test   \n1  https://github.com/soimort/you-get/blob/b746ac...      test   \n2  https://github.com/soimort/you-get/blob/b746ac...      test   \n3  https://github.com/soimort/you-get/blob/b746ac...      test   \n4  https://github.com/soimort/you-get/blob/b746ac...      test   \n\n                               docstring_clean  url_encoded  \n0                         extract video id url          490  \n1  strlist    convert xml url list    biligrab          471  \n2                                    also               464  \n3                                      wrapper          465  \n4                  download dailymot video url          463  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>repo</th>\n      <th>path</th>\n      <th>func_name</th>\n      <th>original_string</th>\n      <th>language</th>\n      <th>code</th>\n      <th>code_tokens</th>\n      <th>docstring</th>\n      <th>docstring_tokens</th>\n      <th>sha</th>\n      <th>url</th>\n      <th>partition</th>\n      <th>docstring_clean</th>\n      <th>url_encoded</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>soimort/you-get</td>\n      <td>src/you_get/extractors/youtube.py</td>\n      <td>YouTube.get_vid_from_url</td>\n      <td>def get_vid_from_url(url):\\n        \"\"\"Extract...</td>\n      <td>python</td>\n      <td>def get_vid_from_url(url):\\n        \"\"\"Extract...</td>\n      <td>['def', 'get_vid_from_url', '(', 'url', ')', '...</td>\n      <td>Extracts video ID from URL.</td>\n      <td>['Extracts', 'video', 'ID', 'from', 'URL', '.']</td>\n      <td>b746ac01c9f39de94cac2d56f665285b0523b974</td>\n      <td>https://github.com/soimort/you-get/blob/b746ac...</td>\n      <td>test</td>\n      <td>extract video id url</td>\n      <td>490</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>soimort/you-get</td>\n      <td>src/you_get/extractors/miomio.py</td>\n      <td>sina_xml_to_url_list</td>\n      <td>def sina_xml_to_url_list(xml_data):\\n    \"\"\"st...</td>\n      <td>python</td>\n      <td>def sina_xml_to_url_list(xml_data):\\n    \"\"\"st...</td>\n      <td>['def', 'sina_xml_to_url_list', '(', 'xml_data...</td>\n      <td>str-&gt;list\\n    Convert XML to URL List.\\n    F...</td>\n      <td>['str', '-', '&gt;', 'list', 'Convert', 'XML', 't...</td>\n      <td>b746ac01c9f39de94cac2d56f665285b0523b974</td>\n      <td>https://github.com/soimort/you-get/blob/b746ac...</td>\n      <td>test</td>\n      <td>strlist    convert xml url list    biligrab</td>\n      <td>471</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>soimort/you-get</td>\n      <td>src/you_get/extractors/fc2video.py</td>\n      <td>makeMimi</td>\n      <td>def makeMimi(upid):\\n    \"\"\"From http://cdn37....</td>\n      <td>python</td>\n      <td>def makeMimi(upid):\\n    \"\"\"From http://cdn37....</td>\n      <td>['def', 'makeMimi', '(', 'upid', ')', ':', 'st...</td>\n      <td>From http://cdn37.atwikiimg.com/sitescript/pub...</td>\n      <td>['From', 'http', ':', '//', 'cdn37', '.', 'atw...</td>\n      <td>b746ac01c9f39de94cac2d56f665285b0523b974</td>\n      <td>https://github.com/soimort/you-get/blob/b746ac...</td>\n      <td>test</td>\n      <td>also</td>\n      <td>464</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>soimort/you-get</td>\n      <td>src/you_get/extractors/fc2video.py</td>\n      <td>fc2video_download</td>\n      <td>def fc2video_download(url, output_dir = '.', m...</td>\n      <td>python</td>\n      <td>def fc2video_download(url, output_dir = '.', m...</td>\n      <td>['def', 'fc2video_download', '(', 'url', ',', ...</td>\n      <td>wrapper</td>\n      <td>['wrapper']</td>\n      <td>b746ac01c9f39de94cac2d56f665285b0523b974</td>\n      <td>https://github.com/soimort/you-get/blob/b746ac...</td>\n      <td>test</td>\n      <td>wrapper</td>\n      <td>465</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>soimort/you-get</td>\n      <td>src/you_get/extractors/dailymotion.py</td>\n      <td>dailymotion_download</td>\n      <td>def dailymotion_download(url, output_dir='.', ...</td>\n      <td>python</td>\n      <td>def dailymotion_download(url, output_dir='.', ...</td>\n      <td>['def', 'dailymotion_download', '(', 'url', ',...</td>\n      <td>Downloads Dailymotion videos by URL.</td>\n      <td>['Downloads', 'Dailymotion', 'videos', 'by', '...</td>\n      <td>b746ac01c9f39de94cac2d56f665285b0523b974</td>\n      <td>https://github.com/soimort/you-get/blob/b746ac...</td>\n      <td>test</td>\n      <td>download dailymot video url</td>\n      <td>463</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test_x = test_df['docstring_clean']\ntest_y = test_df['url_encoded']\n\nprint(len(test_x), len(test_y))","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:07:33.468182Z","iopub.execute_input":"2023-06-09T11:07:33.468544Z","iopub.status.idle":"2023-06-09T11:07:33.476444Z","shell.execute_reply.started":"2023-06-09T11:07:33.468514Z","shell.execute_reply":"2023-06-09T11:07:33.475453Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"500 500\n","output_type":"stream"}]},{"cell_type":"code","source":"train_x = train_df['docstring_clean']\ntrain_y = train_df['url_encoded']","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:07:34.871173Z","iopub.execute_input":"2023-06-09T11:07:34.872250Z","iopub.status.idle":"2023-06-09T11:07:34.877420Z","shell.execute_reply.started":"2023-06-09T11:07:34.872208Z","shell.execute_reply":"2023-06-09T11:07:34.876416Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\n\n# instantiate the vectorizer\nvect = CountVectorizer()\nvect.fit(train_x)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:07:36.672428Z","iopub.execute_input":"2023-06-09T11:07:36.672785Z","iopub.status.idle":"2023-06-09T11:07:36.738568Z","shell.execute_reply.started":"2023-06-09T11:07:36.672755Z","shell.execute_reply":"2023-06-09T11:07:36.737725Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"CountVectorizer()","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\n\n# instantiate the vectorizer\nvect = CountVectorizer()\nvect.fit(test_x)","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:07:38.093177Z","iopub.execute_input":"2023-06-09T11:07:38.093535Z","iopub.status.idle":"2023-06-09T11:07:38.123070Z","shell.execute_reply.started":"2023-06-09T11:07:38.093506Z","shell.execute_reply":"2023-06-09T11:07:38.122026Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"CountVectorizer()","text/html":"<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"x_test_dtm = vect.transform(test_x)\nx_train_dtm = vect.transform(train_x)","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:07:39.697935Z","iopub.execute_input":"2023-06-09T11:07:39.698608Z","iopub.status.idle":"2023-06-09T11:07:39.755584Z","shell.execute_reply.started":"2023-06-09T11:07:39.698576Z","shell.execute_reply":"2023-06-09T11:07:39.754450Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"vect_tunned = CountVectorizer(stop_words='english', ngram_range=(1,2), min_df=0.1, max_df=0.7, max_features=100)","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:07:41.260719Z","iopub.execute_input":"2023-06-09T11:07:41.261109Z","iopub.status.idle":"2023-06-09T11:07:41.266526Z","shell.execute_reply.started":"2023-06-09T11:07:41.261078Z","shell.execute_reply":"2023-06-09T11:07:41.265096Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfTransformer\n\ntfidf_transformer = TfidfTransformer()\n\ntfidf_transformer.fit(x_train_dtm)\nx_train_tfidf = tfidf_transformer.transform(x_train_dtm)\n\nx_train_tfidf","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:07:43.059818Z","iopub.execute_input":"2023-06-09T11:07:43.060394Z","iopub.status.idle":"2023-06-09T11:07:43.077940Z","shell.execute_reply.started":"2023-06-09T11:07:43.060362Z","shell.execute_reply":"2023-06-09T11:07:43.076972Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"<1000x1570 sparse matrix of type '<class 'numpy.float64'>'\n\twith 13019 stored elements in Compressed Sparse Row format>"},"metadata":{}}]},{"cell_type":"code","source":"texts = train_df['docstring_clean']\ntarget = train_df['url_encoded']","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:07:44.714508Z","iopub.execute_input":"2023-06-09T11:07:44.717262Z","iopub.status.idle":"2023-06-09T11:07:44.721773Z","shell.execute_reply.started":"2023-06-09T11:07:44.717226Z","shell.execute_reply":"2023-06-09T11:07:44.720656Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# Calculate the length of our vocabulary\nword_tokenizer = Tokenizer()\nword_tokenizer.fit_on_texts(texts)\n\nvocab_length = len(word_tokenizer.word_index) + 1\nvocab_length","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:07:46.123664Z","iopub.execute_input":"2023-06-09T11:07:46.124343Z","iopub.status.idle":"2023-06-09T11:07:46.173768Z","shell.execute_reply.started":"2023-06-09T11:07:46.124304Z","shell.execute_reply":"2023-06-09T11:07:46.172759Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"3808"},"metadata":{}}]},{"cell_type":"code","source":"def embed(corpus): \n    return word_tokenizer.texts_to_sequences(corpus)\n\nlongest_train = max(texts, key=lambda sentence: len(word_tokenize(sentence)))\nlength_long_sentence = len(word_tokenize(longest_train))\n\ntrain_padded_sentences = pad_sequences(\n    embed(texts), \n    length_long_sentence, \n    padding='post'\n)\n\ntrain_padded_sentences","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:07:47.279645Z","iopub.execute_input":"2023-06-09T11:07:47.280028Z","iopub.status.idle":"2023-06-09T11:07:47.760447Z","shell.execute_reply.started":"2023-06-09T11:07:47.279995Z","shell.execute_reply":"2023-06-09T11:07:47.759289Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"array([[ 105, 2050,  931, ...,    0,    0,    0],\n       [ 821,  150,   28, ...,    0,    0,    0],\n       [ 482,  150, 1399, ...,    0,    0,    0],\n       ...,\n       [  33,   23,  171, ...,    0,    0,    0],\n       [ 338,   28,    3, ...,    0,    0,    0],\n       [ 215, 3807,    2, ...,    0,    0,    0]], dtype=int32)"},"metadata":{}}]},{"cell_type":"code","source":"embeddings_dictionary = dict()\nembedding_dim = 100\n\n# Load GloVe 100D embeddings\nwith open('/kaggle/input/glove-text-file/glove.6B.100d.txt') as fp:\n    for line in fp.readlines():\n        records = line.split()\n        word = records[0]\n        vector_dimensions = np.asarray(records[1:], dtype='float32')\n        embeddings_dictionary [word] = vector_dimensions\n\n# embeddings_dictionary","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:07:48.450335Z","iopub.execute_input":"2023-06-09T11:07:48.450704Z","iopub.status.idle":"2023-06-09T11:08:02.916826Z","shell.execute_reply.started":"2023-06-09T11:07:48.450675Z","shell.execute_reply":"2023-06-09T11:08:02.915886Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":" #Now we will load embedding vectors of those words that appear in the\n# Glove dictionary. Others will be initialized to 0.\n\nembedding_matrix = np.zeros((vocab_length, embedding_dim))\n\nfor word, index in word_tokenizer.word_index.items():\n    embedding_vector = embeddings_dictionary.get(word)\n    if embedding_vector is not None:\n        embedding_matrix[index] = embedding_vector\n        \nembedding_matrix","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:08:05.201544Z","iopub.execute_input":"2023-06-09T11:08:05.201901Z","iopub.status.idle":"2023-06-09T11:08:05.217595Z","shell.execute_reply.started":"2023-06-09T11:08:05.201873Z","shell.execute_reply":"2023-06-09T11:08:05.216640Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n         0.        ,  0.        ],\n       [-0.096096  ,  0.30311999, -0.14951   , ...,  0.2158    ,\n        -1.03349996, -0.35038999],\n       [ 0.10483   , -0.20148   ,  0.20761   , ...,  0.56396002,\n         0.070056  , -0.21981999],\n       ...,\n       [-0.74070001,  0.26899001,  0.79694998, ...,  0.14331   ,\n        -0.066576  , -0.86271   ],\n       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n         0.        ,  0.        ],\n       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n         0.        ,  0.        ]])"},"metadata":{}}]},{"cell_type":"code","source":"# Create a Multinomial Naive Bayes model\nfrom sklearn.naive_bayes import MultinomialNB\nnb = MultinomialNB()\n\n# Train the model\nnb.fit(x_train_dtm, train_y)","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:08:06.623644Z","iopub.execute_input":"2023-06-09T11:08:06.624691Z","iopub.status.idle":"2023-06-09T11:08:06.713487Z","shell.execute_reply.started":"2023-06-09T11:08:06.624649Z","shell.execute_reply":"2023-06-09T11:08:06.712386Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"MultinomialNB()","text/html":"<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"# Make class anf probability predictions\ny_pred_class = nb.predict(x_test_dtm)\ny_pred_prob = nb.predict_proba(x_test_dtm)[:, 1]","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:08:08.776901Z","iopub.execute_input":"2023-06-09T11:08:08.777610Z","iopub.status.idle":"2023-06-09T11:08:08.814371Z","shell.execute_reply.started":"2023-06-09T11:08:08.777567Z","shell.execute_reply":"2023-06-09T11:08:08.813362Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# # calculate accuracy of class predictions\n# from sklearn import metrics\n# import seaborn as sns\n# import matplotlib.pyplot as plt\n# from sklearn.metrics import confusion_matrix\n# import numpy as np\n\n# confusion = confusion_matrix(test_y, y_pred_class)\n# print(confusion)\n\n# print(metrics.accuracy_score(test_y, y_pred_class))\n\n# conf_matrix(metrics.confusion_matrix(test_y, y_pred_class))","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:08:10.811887Z","iopub.execute_input":"2023-06-09T11:08:10.812525Z","iopub.status.idle":"2023-06-09T11:08:10.817018Z","shell.execute_reply.started":"2023-06-09T11:08:10.812491Z","shell.execute_reply":"2023-06-09T11:08:10.816026Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# # Calculate AUC\n# metrics.roc_auc_score(test_y, y_pred_prob, multi_class='ovr')","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:08:12.080073Z","iopub.execute_input":"2023-06-09T11:08:12.080419Z","iopub.status.idle":"2023-06-09T11:08:12.084510Z","shell.execute_reply.started":"2023-06-09T11:08:12.080393Z","shell.execute_reply":"2023-06-09T11:08:12.083589Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.pipeline import Pipeline\n\npipe = Pipeline([('bow', CountVectorizer()), \n                 ('tfid', TfidfTransformer()),  \n                 ('model', MultinomialNB())])","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:08:13.297449Z","iopub.execute_input":"2023-06-09T11:08:13.297810Z","iopub.status.idle":"2023-06-09T11:08:13.312617Z","shell.execute_reply.started":"2023-06-09T11:08:13.297779Z","shell.execute_reply":"2023-06-09T11:08:13.311729Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# Fit the pipeline with the data\npipe.fit(train_x, train_y)\n\ny_pred_class = pipe.predict(test_x)\n\n# print(metrics.accuracy_score(test_y, y_pred_class))\n\n# conf_matrix(metrics.confusion_matrix(test_y, y_pred_class))","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:08:15.675626Z","iopub.execute_input":"2023-06-09T11:08:15.676036Z","iopub.status.idle":"2023-06-09T11:08:15.971482Z","shell.execute_reply.started":"2023-06-09T11:08:15.675999Z","shell.execute_reply":"2023-06-09T11:08:15.970460Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"import xgboost as xgb\n\npipe = Pipeline([\n    ('bow', CountVectorizer()), \n    ('tfid', TfidfTransformer()),  \n    ('model', xgb.XGBClassifier(\n        learning_rate=0.1,\n        max_depth=7,\n        n_estimators=80,\n        use_label_encoder=False,\n        eval_metric='auc',\n        # colsample_bytree=0.8,\n        # subsample=0.7,\n        # min_child_weight=5,\n    ))\n])","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:08:17.159663Z","iopub.execute_input":"2023-06-09T11:08:17.160034Z","iopub.status.idle":"2023-06-09T11:08:17.307803Z","shell.execute_reply.started":"2023-06-09T11:08:17.160003Z","shell.execute_reply":"2023-06-09T11:08:17.306804Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:1395: UserWarning:\n\n`use_label_encoder` is deprecated in 1.7.0.\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Fit the pipeline with the data\npipe.fit(train_x, train_y)\n\ny_pred_class = pipe.predict(test_x)\ny_pred_train = pipe.predict(train_x)\n\nprint('Train: {}'.format(metrics.accuracy_score(train_y, y_pred_train)))\nprint('Test: {}'.format(metrics.accuracy_score(test_y, y_pred_class)))\n\n# conf_matrix(metrics.confusion_matrix(test_y, y_pred_class))","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:08:18.696069Z","iopub.execute_input":"2023-06-09T11:08:18.696427Z","iopub.status.idle":"2023-06-09T11:09:24.390882Z","shell.execute_reply.started":"2023-06-09T11:08:18.696398Z","shell.execute_reply":"2023-06-09T11:09:24.389353Z"},"trusted":true},"execution_count":43,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[43], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m y_pred_class \u001b[38;5;241m=\u001b[39m pipe\u001b[38;5;241m.\u001b[39mpredict(test_x)\n\u001b[1;32m      5\u001b[0m y_pred_train \u001b[38;5;241m=\u001b[39m pipe\u001b[38;5;241m.\u001b[39mpredict(train_x)\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[43mmetrics\u001b[49m\u001b[38;5;241m.\u001b[39maccuracy_score(train_y, y_pred_train)))\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(metrics\u001b[38;5;241m.\u001b[39maccuracy_score(test_y, y_pred_class)))\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# conf_matrix(metrics.confusion_matrix(test_y, y_pred_class))\u001b[39;00m\n","\u001b[0;31mNameError\u001b[0m: name 'metrics' is not defined"],"ename":"NameError","evalue":"name 'metrics' is not defined","output_type":"error"}]},{"cell_type":"markdown","source":"**BERT**","metadata":{}},{"cell_type":"code","source":"# import torch\n# from transformers import BertTokenizer, BertModel\n# import numpy as np\n\n# # Load pre-trained GloVe embeddings\n# glove_path = '/kaggle/input/glove-text-file/glove.6B.100d.txt'  # Path to your GloVe embeddings file\n# glove_embeddings = {}\n\n# with open(glove_path, 'r', encoding='utf-8') as f:\n#     for line in f:\n#         values = line.strip().split(' ')\n#         word = values[0]\n# #         embeddings = np.asarray(values[1:], dtype=np.float32)\n#         glove_embeddings[word] = embeddings\n\n# # Load pre-trained BERT model and tokenizer\n# model_name = 'bert-base-uncased'\n# tokenizer = BertTokenizer.from_pretrained(model_name)\n# model = BertModel.from_pretrained(model_name)\n\n# # Initialize projection layer\n# projection = torch.nn.Linear(100, 768)\n\n# # Example input\n# input_text = \"This is an example sentence.\"\n\n# # Tokenize input text\n# input_ids = tokenizer.encode(input_text, add_special_tokens=True)\n# input_ids = torch.tensor(input_ids).unsqueeze(0)  # Add batch dimension\n\n# # Convert GloVe embeddings to tensor\n# embeddings_tensor = torch.tensor([glove_embeddings[word] for word in tokenizer.get_vocab() if word in glove_embeddings])\n\n# # Project GloVe embeddings to match BERT hidden size\n# projected_embeddings = projection(embeddings_tensor)\n\n# # Initialize BERT model's embedding layer with projected GloVe embeddings\n# model.embeddings.word_embeddings.weight.data = projected_embeddings\n\n# # Forward pass through the model\n# outputs = model(input_ids)\n\n# # Get the contextualized word embeddings for each token\n# contextual_embeddings = outputs.last_hidden_state\n\n# # Print the contextualized word embeddings\n# print(\"Input Text:\", input_text)\n# print(\"Contextualized Word Embeddings:\", contextual_embeddings)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:00:32.437335Z","iopub.execute_input":"2023-06-09T11:00:32.437852Z","iopub.status.idle":"2023-06-09T11:00:32.491701Z","shell.execute_reply.started":"2023-06-09T11:00:32.437818Z","shell.execute_reply":"2023-06-09T11:00:32.490222Z"},"trusted":true},"execution_count":47,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[47], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m         word \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#         embeddings = np.asarray(values[1:], dtype=np.float32)\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m         glove_embeddings[word] \u001b[38;5;241m=\u001b[39m \u001b[43membeddings\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Load pre-trained BERT model and tokenizer\u001b[39;00m\n\u001b[1;32m     17\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m'\u001b[39m\n","\u001b[0;31mNameError\u001b[0m: name 'embeddings' is not defined"],"ename":"NameError","evalue":"name 'embeddings' is not defined","output_type":"error"}]},{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:09:33.867801Z","iopub.execute_input":"2023-06-09T11:09:33.868178Z","iopub.status.idle":"2023-06-09T11:09:45.210176Z","shell.execute_reply.started":"2023-06-09T11:09:33.868141Z","shell.execute_reply":"2023-06-09T11:09:45.208950Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.29.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.14.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (5.4.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.5.5)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.28.2)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.64.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.5.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install --upgrade transformers","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:09:47.810892Z","iopub.execute_input":"2023-06-09T11:09:47.811858Z","iopub.status.idle":"2023-06-09T11:10:07.835838Z","shell.execute_reply.started":"2023-06-09T11:09:47.811821Z","shell.execute_reply":"2023-06-09T11:10:07.834509Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.29.2)\nCollecting transformers\n  Downloading transformers-4.30.0-py3-none-any.whl (7.2 MB)\n\u001b[2K     \u001b[90m\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0mm0:01\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.14.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (5.4.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.5.5)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.28.2)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.64.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.5.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\nInstalling collected packages: transformers\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.29.2\n    Uninstalling transformers-4.29.2:\n      Successfully uninstalled transformers-4.29.2\nSuccessfully installed transformers-4.30.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n\nimport transformers\nfrom tqdm.notebook import tqdm\nfrom tokenizers import BertWordPieceTokenizer","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:10:07.838739Z","iopub.execute_input":"2023-06-09T11:10:07.840967Z","iopub.status.idle":"2023-06-09T11:10:08.087436Z","shell.execute_reply.started":"2023-06-09T11:10:07.840922Z","shell.execute_reply":"2023-06-09T11:10:08.086454Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n    \nexcept:\n    strategy = tf.distribute.get_strategy()\n    \nprint('Number of replicas in sync: ', strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:10:10.337594Z","iopub.execute_input":"2023-06-09T11:10:10.340246Z","iopub.status.idle":"2023-06-09T11:10:10.367882Z","shell.execute_reply.started":"2023-06-09T11:10:10.340205Z","shell.execute_reply":"2023-06-09T11:10:10.366987Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"Number of replicas in sync:  1\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import BertTokenizer\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\ndef bert_encode(data, maximum_length) :\n    input_ids = []\n    attention_masks = []\n\n    for text in data:\n        encoded = tokenizer.encode_plus(\n            text, \n            add_special_tokens=True,\n            max_length=maximum_length,\n            pad_to_max_length=True,\n\n            return_attention_mask=True,\n        )\n        input_ids.append(encoded['input_ids'])\n        attention_masks.append(encoded['attention_mask'])\n        \n    return np.array(input_ids),np.array(attention_masks)","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:10:17.615054Z","iopub.execute_input":"2023-06-09T11:10:17.615426Z","iopub.status.idle":"2023-06-09T11:10:18.859593Z","shell.execute_reply.started":"2023-06-09T11:10:17.615397Z","shell.execute_reply":"2023-06-09T11:10:18.858600Z"},"trusted":true},"execution_count":48,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading ()solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0422ab6cf36946319349116779698ebf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading ()okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2172cec2c6294634a96fe321c7294f8d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading ()lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"519aa1aa552b4e67b1d0bf19584781be"}},"metadata":{}}]},{"cell_type":"code","source":"texts = test_df['docstring_clean']\ntarget = test_df['url_encoded']\n\ntrain_input_ids, train_attention_masks = bert_encode(texts,60)","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:12:28.661403Z","iopub.execute_input":"2023-06-09T11:12:28.661835Z","iopub.status.idle":"2023-06-09T11:12:29.378410Z","shell.execute_reply.started":"2023-06-09T11:12:28.661802Z","shell.execute_reply":"2023-06-09T11:12:29.377437Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning:\n\nThe `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.optimizers import Adam\n\ndef create_model(bert_model):\n    \n    input_ids = tf.keras.Input(shape=(60,),dtype='int32')\n    attention_masks = tf.keras.Input(shape=(60,),dtype='int32')\n\n    output = bert_model([input_ids,attention_masks])\n    output = output[1]\n    output = tf.keras.layers.Dense(32,activation='relu')(output)\n    output = tf.keras.layers.Dropout(0.2)(output)\n    output = tf.keras.layers.Dense(1,activation='sigmoid')(output)\n    \n    model = tf.keras.models.Model(inputs = [input_ids,attention_masks],outputs = output)\n    model.compile(Adam(lr=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:12:35.346921Z","iopub.execute_input":"2023-06-09T11:12:35.347640Z","iopub.status.idle":"2023-06-09T11:12:35.355227Z","shell.execute_reply.started":"2023-06-09T11:12:35.347606Z","shell.execute_reply":"2023-06-09T11:12:35.354130Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"from transformers import TFBertModel\nbert_model = TFBertModel.from_pretrained('bert-large-uncased')","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:12:40.063639Z","iopub.execute_input":"2023-06-09T11:12:40.064028Z","iopub.status.idle":"2023-06-09T11:12:57.377830Z","shell.execute_reply.started":"2023-06-09T11:12:40.063996Z","shell.execute_reply":"2023-06-09T11:12:57.376932Z"},"trusted":true},"execution_count":52,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading ()lve/main/config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb7bd110250047398d4d03b76355edbf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"479b40fea942454f9ec551ff5d12a04e"}},"metadata":{}},{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFBertModel were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"code","source":"model = create_model(bert_model)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:13:02.460249Z","iopub.execute_input":"2023-06-09T11:13:02.460612Z","iopub.status.idle":"2023-06-09T11:13:11.242093Z","shell.execute_reply.started":"2023-06-09T11:13:02.460582Z","shell.execute_reply":"2023-06-09T11:13:11.241129Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_1 (InputLayer)           [(None, 60)]         0           []                               \n                                                                                                  \n input_2 (InputLayer)           [(None, 60)]         0           []                               \n                                                                                                  \n tf_bert_model (TFBertModel)    TFBaseModelOutputWi  335141888   ['input_1[0][0]',                \n                                thPoolingAndCrossAt               'input_2[0][0]']                \n                                tentions(last_hidde                                               \n                                n_state=(None, 60,                                                \n                                1024),                                                            \n                                 pooler_output=(Non                                               \n                                e, 1024),                                                         \n                                 past_key_values=No                                               \n                                ne, hidden_states=N                                               \n                                one, attentions=Non                                               \n                                e, cross_attentions                                               \n                                =None)                                                            \n                                                                                                  \n dense (Dense)                  (None, 32)           32800       ['tf_bert_model[0][1]']          \n                                                                                                  \n dropout_73 (Dropout)           (None, 32)           0           ['dense[0][0]']                  \n                                                                                                  \n dense_1 (Dense)                (None, 1)            33          ['dropout_73[0][0]']             \n                                                                                                  \n==================================================================================================\nTotal params: 335,174,721\nTrainable params: 335,174,721\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model = create_model(bert_model)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:13:24.718784Z","iopub.execute_input":"2023-06-09T11:13:24.719171Z","iopub.status.idle":"2023-06-09T11:13:28.458315Z","shell.execute_reply.started":"2023-06-09T11:13:24.719139Z","shell.execute_reply":"2023-06-09T11:13:28.457345Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"Model: \"model_1\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_3 (InputLayer)           [(None, 60)]         0           []                               \n                                                                                                  \n input_4 (InputLayer)           [(None, 60)]         0           []                               \n                                                                                                  \n tf_bert_model (TFBertModel)    TFBaseModelOutputWi  335141888   ['input_3[0][0]',                \n                                thPoolingAndCrossAt               'input_4[0][0]']                \n                                tentions(last_hidde                                               \n                                n_state=(None, 60,                                                \n                                1024),                                                            \n                                 pooler_output=(Non                                               \n                                e, 1024),                                                         \n                                 past_key_values=No                                               \n                                ne, hidden_states=N                                               \n                                one, attentions=Non                                               \n                                e, cross_attentions                                               \n                                =None)                                                            \n                                                                                                  \n dense_2 (Dense)                (None, 32)           32800       ['tf_bert_model[1][1]']          \n                                                                                                  \n dropout_74 (Dropout)           (None, 32)           0           ['dense_2[0][0]']                \n                                                                                                  \n dense_3 (Dense)                (None, 1)            33          ['dropout_74[0][0]']             \n                                                                                                  \n==================================================================================================\nTotal params: 335,174,721\nTrainable params: 335,174,721\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Extract loss and accuracy values from the training history\nloss = history['loss']\nval_loss = history['val_loss']\naccuracy = history['accuracy']\nval_accuracy = history['val_accuracy']\n\n# Plot the learning curves\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.plot(accuracy, label='Training Accuracy')\nplt.plot(val_accuracy, label='Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Metrics')\nplt.title('Learning Curves')\nplt.legend()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:21:24.929159Z","iopub.execute_input":"2023-06-09T11:21:24.929718Z","iopub.status.idle":"2023-06-09T11:21:25.028814Z","shell.execute_reply.started":"2023-06-09T11:21:24.929677Z","shell.execute_reply":"2023-06-09T11:21:25.022317Z"},"trusted":true},"execution_count":62,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[62], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Extract loss and accuracy values from the training history\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mhistory\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n","\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"],"ename":"NameError","evalue":"name 'history' is not defined","output_type":"error"}]},{"cell_type":"code","source":"plot_learning_curves(history, [['loss', 'val_loss'],['accuracy', 'val_accuracy']])","metadata":{"execution":{"iopub.status.busy":"2023-06-09T11:13:33.131948Z","iopub.execute_input":"2023-06-09T11:13:33.132350Z","iopub.status.idle":"2023-06-09T11:13:33.186922Z","shell.execute_reply.started":"2023-06-09T11:13:33.132319Z","shell.execute_reply":"2023-06-09T11:13:33.185647Z"},"trusted":true},"execution_count":55,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplot_learning_curves\u001b[49m(history, [[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m],[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n","\u001b[0;31mNameError\u001b[0m: name 'plot_learning_curves' is not defined"],"ename":"NameError","evalue":"name 'plot_learning_curves' is not defined","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}